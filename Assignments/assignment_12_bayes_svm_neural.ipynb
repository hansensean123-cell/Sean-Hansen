{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansensean123-cell/Sean-Hansen/blob/main/Assignments/assignment_12_bayes_svm_neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1SKdBXl6lPz"
      },
      "source": [
        "# Assignment 12: Predicting Hotel Booking Cancellations  \n",
        "## Models: Na√Øve Bayes, Support Vector Machine (SVM), and Neural Network\n",
        "\n",
        "**Objectives:**\n",
        "- Understand how to use classification models (Na√Øve Bayes, SVM, Neural Networks) to predict hotel cancellations.\n",
        "- Compare models in terms of accuracy, complexity, and business relevance.\n",
        "- Interpret and communicate model results from a business perspective.\n",
        "\n",
        "## Business Scenario\n",
        "\n",
        "You work as a data analyst for a hospitality group that manages both **Resort** and **City Hotels**. One major challenge in operations is the unpredictability of **booking cancellations**, which affects staffing, inventory, and revenue planning.\n",
        "\n",
        "You‚Äôve been asked to use historical booking data to predict whether a future booking will be canceled. Your insights will help management plan more effectively.\n",
        "\n",
        "\n",
        "Your task is to:\n",
        "1. Build and evaluate three models: Na√Øve Bayes, SVM, and Neural Network.\n",
        "2. Compare performance.\n",
        "3. Recommend which model is best suited for the business needs.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Assignments/assignment_12_bayes_svm_neural.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhFn2i156aZz"
      },
      "source": [
        "## Dataset Description: Hotel Bookings\n",
        "\n",
        "This dataset contains booking information for two types of hotels: a **city hotel** and a **resort hotel**. Each record corresponds to a single booking and includes various details about the reservation, customer demographics, booking source, and whether the booking was canceled.\n",
        "\n",
        "**Source**: [GitHub - TidyTuesday: Hotel Bookings](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md)\n",
        "\n",
        "### Key Use Cases\n",
        "- Understand customer booking behavior\n",
        "- Explore factors related to cancellations\n",
        "- Segment guests based on booking characteristics\n",
        "- Compare city vs. resort hotel performance\n",
        "\n",
        "### Data Dictionary\n",
        "\n",
        "| Variable | Type | Description |\n",
        "|----------|------|-------------|\n",
        "| `hotel` | character | Hotel type: City or Resort |\n",
        "| `is_canceled` | integer | 1 = Canceled, 0 = Not Canceled |\n",
        "| `lead_time` | integer | Days between booking and arrival |\n",
        "| `arrival_date_year` | integer | Year of arrival |\n",
        "| `arrival_date_month` | character | Month of arrival |\n",
        "| `stays_in_weekend_nights` | integer | Nights stayed on weekends |\n",
        "| `stays_in_week_nights` | integer | Nights stayed on weekdays |\n",
        "| `adults` | integer | Number of adults |\n",
        "| `children` | integer | Number of children |\n",
        "| `babies` | integer | Number of babies |\n",
        "| `meal` | character | Type of meal booked |\n",
        "| `country` | character | Country code of origin |\n",
        "| `market_segment` | character | Booking source (e.g., Direct, Online TA) |\n",
        "| `distribution_channel` | character | Booking channel used |\n",
        "| `is_repeated_guest` | integer | 1 = Repeated guest, 0 = New guest |\n",
        "| `previous_cancellations` | integer | Past booking cancellations |\n",
        "| `previous_bookings_not_canceled` | integer | Past bookings not canceled |\n",
        "| `reserved_room_type` | character | Initially reserved room type |\n",
        "| `assigned_room_type` | character | Room type assigned at check-in |\n",
        "| `booking_changes` | integer | Number of booking modifications |\n",
        "| `deposit_type` | character | Deposit type (No Deposit, Non-Refund, etc.) |\n",
        "| `agent` | character | Agent ID who made the booking |\n",
        "| `company` | character | Company ID (if booking through company) |\n",
        "| `days_in_waiting_list` | integer | Days on the waiting list |\n",
        "| `customer_type` | character | Booking type: Contract, Transient, etc. |\n",
        "| `adr` | float | Average Daily Rate (price per night) |\n",
        "| `required_car_parking_spaces` | integer | Requested parking spots |\n",
        "| `total_of_special_requests` | integer | Number of special requests made |\n",
        "| `reservation_status` | character | Final status (Canceled, No-Show, Check-Out) |\n",
        "| `reservation_status_date` | date | Date of the last status update |\n",
        "\n",
        "This dataset is ideal for classification, segmentation, and trend analysis exercises.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuLnp9NW60ga"
      },
      "source": [
        "## 1. Load and Prepare the Hotel Booking Dataset\n",
        "\n",
        "**Business framing:**  \n",
        "Your hotel client wants to understand which bookings are most at risk of being canceled. But before modeling, your job is to prepare the data to ensure clean and reliable input.\n",
        "\n",
        "### Do the following:\n",
        "- Load the `hotels.csv` file\n",
        "- Remove or impute missing values\n",
        "- Encode categorical variables\n",
        "- Create your `X` (features) and `y` (target = `is_canceled`)\n",
        "- Split the data into training and test sets (70/30)\n",
        "\n",
        "### In Your Response:\n",
        "1. How many total rows and columns are in the dataset?\n",
        "2. What types of features (categorical, numerical) are included?\n",
        "3. What steps did you take to clean or prepare the data?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aW_4Kup75Fe"
      },
      "outputs": [],
      "source": [
        "# Add code here üîß\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/hotels.csv')\n",
        "print(\"DataFrame loaded successfully. First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"Missing values before imputation:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n",
        "df['children'] = df['children'].fillna(df['children'].mode()[0])\n",
        "df['country'] = df['country'].fillna(df['country'].mode()[0])\n",
        "df['agent'] = df['agent'].fillna(0)\n",
        "df['company'] = df['company'].fillna(0)\n",
        "\n",
        "print(\"Missing values after imputation:\")\n",
        "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n",
        "print(\"Categorical columns identified:\")\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "print(categorical_cols)\n",
        "\n",
        "df['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'])\n",
        "\n",
        "# Drop reservation_status and reservation_status_date as they are direct outcomes of cancellation or date of final status\n",
        "df = df.drop(columns=['reservation_status', 'reservation_status_date'])\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"Categorical columns to encode:\")\n",
        "print(categorical_cols)\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"DataFrame after one-hot encoding. First 5 rows:\")\n",
        "print(df_encoded.head())\n",
        "print(\"Shape after encoding:\", df_encoded.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_encoded.drop('is_canceled', axis=1)\n",
        "y = df_encoded['is_canceled']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIjkqBr975N5"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "The dataset initially contained 119,390 rows and 32 columns. After one-hot encoding and dropping 'reservation_status' and 'reservation_status_date', the encoded DataFrame (df_encoded) has 119,390 rows and 248 columns.\n",
        "The dataset includes both numerical and categorical features. Numerical features include lead_time, arrival_date_year, arrival_date_week_number, arrival_date_day_of_month, stays_in_weekend_nights, stays_in_week_nights, adults, children, babies, is_repeated_guest, previous_cancellations, previous_bookings_not_canceled, booking_changes, agent, company, days_in_waiting_list, adr, required_car_parking_spaces, and total_of_special_requests. Categorical features, before encoding, included hotel, arrival_date_month, meal, country, market_segment, distribution_channel, reserved_room_type, assigned_room_type, deposit_type, customer_type, reservation_status, and reservation_status_date.\n",
        "The following steps were taken to clean and prepare the data:\n",
        "Missing Value Imputation: Missing values in children and country columns were imputed with their respective modes. Missing values in agent and company columns were filled with 0.\n",
        "Feature Engineering: The reservation_status_date column was converted to datetime objects.\n",
        "Column Dropping: The reservation_status and reservation_status_date columns were dropped because they directly reflect the outcome (cancellation status) and are not suitable as predictive features.\n",
        "Categorical Encoding: All remaining categorical columns were converted into numerical format using one-hot encoding (pd.get_dummies) with drop_first=True to avoid multicollinearity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7kYLDd37jb2"
      },
      "source": [
        "## 2. Build a Na√Øve Bayes Model\n",
        "\n",
        "**Business framing:**  \n",
        "Na√Øve Bayes is a quick, baseline model often used for early testing or simple classification problems.\n",
        "\n",
        "### Do the following:\n",
        "- Train a Na√Øve Bayes classifier on your training data\n",
        "- Use it to predict on your test data\n",
        "- Print a classification report and confusion matrix\n",
        "\n",
        "### In Your Response:\n",
        "1. How accurate is this model?\n",
        "2. Where might this model be useful for the hotel (e.g. real-time alerts, operational decisions)?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhdXaDOv790n"
      },
      "outputs": [],
      "source": [
        "# Add code here üîß\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Instantiate the Gaussian Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Na√Øve Bayes model trained successfully.\")\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Instantiate the Gaussian Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Na√Øve Bayes model trained successfully.\")\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Classification Report for Na√Øve Bayes Model:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "print(\"\\nConfusion Matrix for Na√Øve Bayes Model:\")\n",
        "print(confusion_matrix(y_test, y_pred_nb))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tye9Jpkp7-RQ"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1.\n",
        "\n",
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JCON2FZ7mCh"
      },
      "source": [
        "## 3. Build a Support Vector Machine (SVM) Model\n",
        "\n",
        "**Business framing:**  \n",
        "SVM can model more complex relationships and is useful when customer behavior patterns aren't linear or obvious.\n",
        "\n",
        "### Do the following:\n",
        "- Train an SVM classifier (use RBF kernel)\n",
        "- Make predictions and evaluate with classification metrics\n",
        "\n",
        "### In Your Response:\n",
        "1. How well does the model perform?\n",
        "2. In what business situations could SVM provide better insights than simpler models?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NRUJ09E8Cfo"
      },
      "outputs": [],
      "source": [
        "# Add code here üîß\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data scaled successfully for SVM.\")\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize an SVC model with an RBF kernel\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Train the SVM model using the scaled training data\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"SVM model trained successfully.\")\n",
        "\n",
        "# Make predictions on the scaled test data\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "print(\"Predictions made successfully on test data for SVM.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82rLQlfL8C5M"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1.\n",
        "\n",
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrtjL41z7oMf"
      },
      "source": [
        "## 4. Build a Neural Network Model\n",
        "\n",
        "**Business framing:**  \n",
        "Neural networks are flexible and powerful, though they are harder to explain. They may work well when subtle patterns exist in the data.\n",
        "\n",
        "### Do the following:\n",
        "- Build a MLBClassifier model using the neural_network package from sklearn\n",
        "- Choose a simple architecture (e.g., 2 hidden layers)\n",
        "- Evaluate accuracy and performance\n",
        "\n",
        "### In Your Response:\n",
        "1. How does this model compare to the others?\n",
        "2. Would the business be comfortable using a ‚Äúblack box‚Äù model like this? Why or why not?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Td5awh38GsD"
      },
      "outputs": [],
      "source": [
        "# Add code here üîß"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vpFx5YK8IKM"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1.\n",
        "\n",
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhhTjrAi7qYG"
      },
      "source": [
        "## 5. Compare All Three Models\n",
        "\n",
        "### Do the following:\n",
        "- Print and compare the accuracy of Na√Øve Bayes, SVM, and Neural Network models\n",
        "- Summarize which model performed best\n",
        "\n",
        "### In Your Response:\n",
        "1. Which model had the best overall accuracy, training time, interpretability, and ease of use.\n",
        "2. Would you recommend this model for deployment, and why?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjxJKIU18OGh"
      },
      "outputs": [],
      "source": [
        "# Add code here üîß"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_u8OnK-8OTh"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1.\n",
        "\n",
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrTu2yAG7tWx"
      },
      "source": [
        "## 6. Final Business Recommendation\n",
        "\n",
        "### In Your Response:\n",
        "1. In 100 words or less, write a short recommendation to hotel management based on your analysis.\n",
        "\n",
        "Possible info to include:\n",
        "- Which model do you recommend implementing?\n",
        "- What business problem does it help solve?\n",
        "- Are there any risks or limitations?\n",
        "- What additional data might improve the results in the future?\n",
        "2. How does this relate to your customized learning outcome you created in canvas?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7xzbER18WBS"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1.\n",
        "\n",
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9axyvpLumoS"
      },
      "source": [
        "## Submission Instructions\n",
        "‚úÖ Checklist:\n",
        "- All code cells run without error\n",
        "- All markdown responses are complete\n",
        "- Submit on Canvas as instructed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWyBVGhFumoS"
      },
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"assignment_12_LastnameFirstname.ipynb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6b37a2a"
      },
      "source": [
        "# Task\n",
        "Load the `hotels.csv` dataset, handle missing values, encode categorical variables, define features (X) and target (y = 'is_canceled'), and split the data into 70/30 training and testing sets; then, report the total number of rows and columns, the types of features included, and a summary of the data cleaning and preparation steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07c0ff97"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the 'hotels.csv' file into a pandas DataFrame for initial inspection and processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8711d12b"
      },
      "source": [
        "**Reasoning**:\n",
        "To load the dataset, I need to import the pandas library and then use its `read_csv` function to load the 'hotels.csv' file into a DataFrame. Then, I will display the first few rows to confirm successful loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "374ee1c2"
      },
      "source": [
        "## Train Naive Bayes Classifier\n",
        "\n",
        "### Subtask:\n",
        "Train a Na√Øve Bayes classifier on the preprocessed training data (`X_train`, `y_train`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc6138f1"
      },
      "source": [
        "**Reasoning**:\n",
        "To train a Na√Øve Bayes classifier, I need to import the GaussianNB model from sklearn.naive_bayes, instantiate it, and then fit it to the training data (X_train, y_train).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99b16b92",
        "outputId": "48355a9b-b135-4308-f22b-f6f3f9418ed6"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Instantiate the Gaussian Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Na√Øve Bayes model trained successfully.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Na√Øve Bayes model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "771889db"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Na√Øve Bayes model is trained, I will use it to make predictions on the test data (`X_test`). This is a necessary step before evaluating the model's performance with a classification report and confusion matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6427db04",
        "outputId": "990ddf48-0e04-4c88-d54b-7fcde2a1a61b"
      },
      "source": [
        "y_pred_nb = nb_model.predict(X_test)\n",
        "print(\"Predictions made successfully on test data.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions made successfully on test data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57fb3cd5"
      },
      "source": [
        "**Reasoning**:\n",
        "With the predictions made, the next logical step is to evaluate the Na√Øve Bayes model's performance by generating a classification report and a confusion matrix to understand its accuracy, precision, recall, and F1-score, as well as the types of errors it makes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7015c7c9",
        "outputId": "5634fc80-aafa-459a-ab14-ef0c30cff579"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Classification Report for Na√Øve Bayes Model:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "print(\"\\nConfusion Matrix for Na√Øve Bayes Model:\")\n",
        "print(confusion_matrix(y_test, y_pred_nb))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Na√Øve Bayes Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.33      0.47     22478\n",
            "           1       0.45      0.91      0.60     13339\n",
            "\n",
            "    accuracy                           0.54     35817\n",
            "   macro avg       0.65      0.62      0.54     35817\n",
            "weighted avg       0.71      0.54      0.52     35817\n",
            "\n",
            "\n",
            "Confusion Matrix for Na√Øve Bayes Model:\n",
            "[[ 7308 15170]\n",
            " [ 1172 12167]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da64b7d2"
      },
      "source": [
        "## Build a Support Vector Machine (SVM) Model\n",
        "\n",
        "### Subtask:\n",
        "Train an SVM classifier (use RBF kernel), make predictions, and evaluate with classification metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2ecb6b9"
      },
      "source": [
        "## Scale Data for SVM\n",
        "\n",
        "### Subtask:\n",
        "Initialize a `StandardScaler` and scale `X_train` and `X_test`.\n",
        "\n",
        "**Reasoning**:\n",
        "Scaling features is essential for SVMs because they rely on distance metrics. Features with larger values might disproportionately influence the model. `StandardScaler` will transform the data such that it has a mean of 0 and a standard deviation of 1, which is optimal for many machine learning algorithms, including SVM with an RBF kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "047673f7"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the data for the SVM model as per the instructions, I need to import the `StandardScaler`, fit it on the training data, and then transform both the training and test sets. This ensures that the features are scaled appropriately for SVM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a23a0357",
        "outputId": "c524fcc6-6ec0-4c39-bdbc-f49fe105a6db"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data scaled successfully for SVM.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scaled successfully for SVM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62a9c321"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data is scaled, I will initialize an SVC model with an RBF kernel, train it on the scaled training data, and then make predictions on the scaled test data. This aligns with the subtask instructions to train an SVM classifier and make predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6034d8c",
        "outputId": "b8dd09d6-95cf-4e58-963f-ff81b5e4dab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize an SVC model with an RBF kernel\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Train the SVM model using the scaled training data\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"SVM model trained successfully.\")\n",
        "\n",
        "# Make predictions on the scaled test data\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "print(\"Predictions made successfully on test data for SVM.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM model trained successfully.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}